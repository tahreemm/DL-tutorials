{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This code implements and explain an end to end pipeline of a simple CNN on MNIST dataset. The steps are following:</b> \n",
    "\n",
    "1. Loading and preprocessing\n",
    "2. Defining the CNN model\n",
    "3. Setting up the loss function and Optimizer \n",
    "4. Training the Model\n",
    "5. Evaluating the test data\n",
    "6. Making predictions on new data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/codespace/.python/current/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: torch==2.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision \n",
    "from torchvision import transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup preprocessing for dataset to convert numpy array of pixels to \n",
    "# tensor for easier processing which includes transforming to tensors \n",
    "# normalizing the pixel values in the range for easier convergence \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, ), (0.5, ))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the images before and after the tranform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading MNIST dataset with and without transform\n",
    "mnist_original = datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_tranformed = datasets.MNIST(root='./data', train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample image and its label \n",
    "index = 0 \n",
    "original_image, label = mnist_original[index]\n",
    "transformed_image, _ = mnist_tranformed[index]\n",
    "# Convert the transformed image from tensor to numpy for visualization\n",
    "# squeeze() removes the channel dimension  \n",
    "transformed_image_np = transformed_image.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the images \n",
    "fig, axs = plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "#original image \n",
    "axs[0].imshow(original_image)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "#transformed Image \n",
    "axs[1].imshow(transformed_image_np)\n",
    "axs[1].set_title(\"transformed Image\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Values:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.9764706 , -0.85882354, -0.85882354,\n",
       "        -0.85882354, -0.01176471,  0.06666672,  0.37254906, -0.79607844,\n",
       "         0.30196083,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.7647059 , -0.7176471 ,\n",
       "        -0.26274508,  0.20784318,  0.33333337,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.7647059 ,  0.34901965,\n",
       "         0.9843137 ,  0.8980392 ,  0.5294118 , -0.4980392 , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.6156863 ,  0.8666667 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.96862745, -0.27058822, -0.35686272,\n",
       "        -0.35686272, -0.56078434, -0.69411767, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.85882354,  0.7176471 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 ,\n",
       "         0.427451  ,  0.9372549 ,  0.8901961 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.372549  ,  0.22352946,\n",
       "        -0.1607843 ,  0.9843137 ,  0.9843137 ,  0.60784316, -0.9137255 ,\n",
       "        -1.        , -0.6627451 ,  0.20784318, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.8901961 ,\n",
       "        -0.99215686,  0.20784318,  0.9843137 , -0.29411763, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.09019613,  0.9843137 ,  0.4901961 , -0.9843137 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.9137255 ,  0.4901961 ,  0.9843137 , -0.45098037,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.7254902 ,  0.8901961 ,  0.7647059 ,\n",
       "         0.254902  , -0.15294117, -0.99215686, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.36470586,  0.88235295,\n",
       "         0.9843137 ,  0.9843137 , -0.06666666, -0.8039216 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.64705884,\n",
       "         0.45882356,  0.9843137 ,  0.9843137 ,  0.17647064, -0.7882353 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.8745098 , -0.27058822,  0.9764706 ,  0.9843137 ,  0.4666667 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.9529412 ,  0.9843137 ,  0.9529412 ,\n",
       "        -0.4980392 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.6392157 ,\n",
       "         0.0196079 ,  0.43529415,  0.9843137 ,  0.9843137 ,  0.62352943,\n",
       "        -0.9843137 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.69411767,  0.16078436,  0.79607844,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9607843 ,  0.427451  ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.8117647 , -0.10588235,  0.73333335,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.5764706 , -0.38823527, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.81960785, -0.4823529 ,\n",
       "         0.67058825,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
       "         0.5529412 , -0.36470586, -0.9843137 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.85882354,  0.3411765 ,  0.7176471 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5294118 , -0.372549  ,\n",
       "        -0.92941177, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -0.5686275 ,\n",
       "         0.34901965,  0.77254903,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
       "         0.9843137 ,  0.9137255 ,  0.04313731, -0.9137255 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        ,  0.06666672,\n",
       "         0.9843137 ,  0.9843137 ,  0.9843137 ,  0.6627451 ,  0.05882359,\n",
       "         0.03529418, -0.8745098 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The normalization effect can witnessed by printing both \n",
    "# images and their pixel values \n",
    "original_image_np = np.array(original_image)\n",
    "print(\"Pixel Values:\\n\", original_image_np)\n",
    "transformed_image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with transformations\n",
    "def get_data_loaders(batch_size=32):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transform), batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MNIST, self).__init__()\n",
    "        # First convolution layer \n",
    "        # Why in_channels=1? Because MNIST images are grayscale (single channel)\n",
    "        # Why padding=1? To maintain the spatial dimensions after convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        #The pooling window is 2x2, meaning it will look at a 2x2 grid of values at a time.\n",
    "        #The stride controls how much the window shifts each time. \n",
    "        # With a stride of 2, the window will move 2 pixels at a time, meaning it will not overlap with its previous position.\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1) \n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer with 10 classes \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = CNN_MNIST().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Set model to training mode, this is a built in method in torch.nn\n",
    "    # model.train() informs torch to switch the model for training which is essential \n",
    "    # for certain operations such as batch normalization or drop out \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "            \n",
    "            optimizer.zero_grad()  # Flushes the gradients from previous batch\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss by comparing the 10 raw values \n",
    "            #returned for each training sample in the outputs \n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            #Extract loss value from the tensor\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "def evaluate(model, test_loader, device):\n",
    "    # This is particularly important for layers that behave differently during training and \n",
    "    # inference, such as dropout and batch normalization.\n",
    "    #Dropout layers, which randomly set some of the units to zero during training to prevent \n",
    "    # overfitting, will no longer drop any units when the model is in evaluation mode. \n",
    "    # Instead, they will use the full set of activations. Batch normalization layers, which \n",
    "    # normalize activations during training based on the current batch statistics (mean and \n",
    "    # variance), will instead use running statistics accumulated during training when in \n",
    "    # evaluation mode. This ensures more stable predictions during inference.\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): #Disables gradient tracking inside the with block.\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1) #This function returns the maximum value along\n",
    "            #the specified dimension (dimension 1, which is the class dimension here).\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CNN_MNIST().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_loader, test_loader = get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0691\n",
      "Epoch 2/5, Loss: 0.0385\n",
      "Epoch 3/5, Loss: 0.0273\n",
      "Epoch 4/5, Loss: 0.0207\n",
      "Epoch 5/5, Loss: 0.0160\n",
      "Test Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explain about in_channels and out_channels which are features \n",
    "### Explain about how stride moves the filters\n",
    "### Explain convolution and pooling \n",
    "### Explain about the channels, why channels remain the same spatial dimensions are reduced "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
